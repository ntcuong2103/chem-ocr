{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lit_bttr import LitBTTR\n",
    "from PIL import Image\n",
    "from torchvision.transforms import ToTensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import zipfile\n",
    "\n",
    "\n",
    "with zipfile.ZipFile('crocs-train-zips/test-B/testB.zip', \"r\") as f:\n",
    "    fns = f.namelist()\n",
    "    with f.open('testB/test_00000.jpg', \"r\") as img_f:\n",
    "        img = Image.open(img_f).copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = img.convert('L')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.array(img).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ckpt = 'lightning_logs/version_22/checkpoints/epoch=9-step=17260-val_loss=0.3059.ckpt'\n",
    "img_path = 'train/train_14339.jpg'\n",
    "device = 'cuda:1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LitBTTR.load_from_checkpoint(ckpt)\n",
    "model.eval()\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pil_img = Image.open(img_path)\n",
    "pil_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datamodule import ScaleToLimitRange\n",
    "from torchvision.transforms import Compose\n",
    "from torchvision import transforms\n",
    "\n",
    "transform = Compose([ScaleToLimitRange(), transforms.ToTensor()])\n",
    "img_trans = transform(img)\n",
    "img_trans = img_trans.to('cuda:1')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tgt_str = '\\\\chemfig { C H O H -[:90] C H O H } + O _ { 2 } \\\\xrightarrow [ \\\\triangle ] { A g æˆ– C u } \\\\chemfig { C H O -[:90] C H O } + 2 H _ { 2 } O'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datamodule import vocab\n",
    "tgt_indices = vocab.words2indices(tgt_str.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import to_bi_tgt_out\n",
    "\n",
    "tgt, out = to_bi_tgt_out([tgt_indices], device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tgt[0].cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab.indices2label(tgt[0].cpu().numpy()), vocab.indices2label(tgt[1].cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab.indices2label(out[0].cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "out_logits = model.forward(img_trans.unsqueeze(0), torch.ones_like(img_trans), tgt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab.word2idx['\\\\Chemfig']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab.indices2label( out_logits.argmax(-1)[0].detach().cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "' '.join(vocab.indices2label( out_logits.argmax(-1)[1].detach().cpu().numpy()).split()[::-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyp = model.beam_search(img_trans, beam_size=5, max_len=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(hyp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch-tf-lt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  },
  "metadata": {
   "interpreter": {
    "hash": "5c10e69c8be8251d2427514ec023c1218910a696d384ef8f31a18bcc6602a077"
   }
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
